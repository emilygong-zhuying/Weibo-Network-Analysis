{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emilygong/miniconda3/envs/paddle_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import paddle\n",
    "import paddlenlp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "def read(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            words = line[:-3]\n",
    "            labels = line[-2]\n",
    "            yield {'text': words, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_dataset(read, data_path='train_clean.txt',lazy=False)\n",
    "dev_ds = load_dataset(read, data_path='dev_clean.txt',lazy=False)\n",
    "test_ds = load_dataset(read, data_path='test_clean.txt',lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-02 11:40:08,224] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification'> to load 'ernie-3.0-medium-zh'.\u001b[0m\n",
      "\u001b[32m[2022-12-02 11:40:08,228] [    INFO]\u001b[0m - Already cached /home/emilygong/.paddlenlp/models/ernie-3.0-medium-zh/ernie_3.0_medium_zh.pdparams\u001b[0m\n",
      "\u001b[32m[2022-12-02 11:40:16,140] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-3.0-medium-zh'.\u001b[0m\n",
      "\u001b[32m[2022-12-02 11:40:16,144] [    INFO]\u001b[0m - Already cached /home/emilygong/.paddlenlp/models/ernie-3.0-medium-zh/ernie_3.0_medium_zh_vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-12-02 11:40:16,177] [    INFO]\u001b[0m - tokenizer config file saved in /home/emilygong/.paddlenlp/models/ernie-3.0-medium-zh/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-12-02 11:40:16,179] [    INFO]\u001b[0m - Special tokens file saved in /home/emilygong/.paddlenlp/models/ernie-3.0-medium-zh/special_tokens_map.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"ernie-3.0-medium-zh\"\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=len(train_ds.label_list))\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example(example, tokenizer):\n",
    "    tokenized_example = tokenizer(text=example['text'], max_seq_length=128)\n",
    "    # 加上label用于训练\n",
    "    tokenized_example['label'] = [int(example['labels'])]\n",
    "    return tokenized_example\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "trans_func = partial(convert_example, tokenizer=tokenizer)\n",
    "\n",
    "train_ds = train_ds.map(trans_func)\n",
    "dev_ds = dev_ds.map(trans_func)\n",
    "test_ds = test_ds.map(trans_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.io import DataLoader, BatchSampler\n",
    "from paddlenlp.data import DataCollatorWithPadding\n",
    "\n",
    "collate_fn = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 定义BatchSampler，选择批大小和是否随机乱序，进行DataLoader\n",
    "train_batch_sampler = BatchSampler(train_ds, batch_size=32, shuffle=True)\n",
    "dev_batch_sampler = BatchSampler(dev_ds, batch_size=64, shuffle=False)\n",
    "train_data_loader = DataLoader(dataset=train_ds, batch_sampler=train_batch_sampler, collate_fn=collate_fn)\n",
    "dev_data_loader = DataLoader(dataset=dev_ds, batch_sampler=dev_batch_sampler, collate_fn=collate_fn)\n",
    "test_batch_sampler = BatchSampler(test_ds, batch_size=32, shuffle=False)\n",
    "test_data_loader = DataLoader(dataset=test_ds, batch_sampler=test_batch_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam优化器、交叉熵损失函数、accuracy评价指标\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=2e-5, parameters=model.parameters())\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.nn.functional as F\n",
    "def evaluate(model, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(data_loader, start=1):\n",
    "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
    "        # 计算模型输出、损失函数值、分类概率值、准确率\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "    print(\"eval accu: %.5f\" % (acc))\n",
    "    model.train()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载ERNIR 3.0最佳模型参数\n",
    "params_path = 'ernie_ckpt_cleaner/model_state.pdparams'\n",
    "state_dict = paddle.load(params_path)\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNIE 3.0-Medium 在weibo_senti的dev集表现 eval accu: 0.77066\n"
     ]
    }
   ],
   "source": [
    "print('ERNIE 3.0-Medium 在weibo_senti的dev集表现', end=' ')\n",
    "eval_acc = evaluate(model, metric, dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNIE 3.0-Medium 在weibo_senti的test集表现 eval accu: 0.77453\n"
     ]
    }
   ],
   "source": [
    "print('ERNIE 3.0-Medium 在weibo_senti的test集表现', end=' ')\n",
    "eval_acc = evaluate(model, metric, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测分类结果\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "label_map = {0: '负面', 1: '正面'}\n",
    "results = []\n",
    "model.eval()\n",
    "for batch in test_data_loader:\n",
    "    input_ids, token_type_ids = batch['input_ids'], batch['token_type_ids']\n",
    "    logits = model(batch['input_ids'], batch['token_type_ids'])\n",
    "    probs = F.softmax(logits, axis=-1)\n",
    "    idx = paddle.argmax(probs, axis=1).numpy()\n",
    "    idx = idx.tolist()\n",
    "    preds = [label_map[i] for i in idx]\n",
    "    results.extend(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_test_ds = load_dataset(read, data_path='actual_test_clean.txt',lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def convert_example(example, tokenizer):\n",
    "    tokenized_example = tokenizer(text=example['text'], max_seq_length=128)\n",
    "    # 加上label用于训练\n",
    "    tokenized_example['label'] = [int(example['labels'])]\n",
    "    return tokenized_example\n",
    "\n",
    "trans_func = partial(convert_example, tokenizer=tokenizer)\n",
    "\n",
    "actual_test_ds = actual_test_ds.map(trans_func)\n",
    "\n",
    "# 进行采样组batch\n",
    "collate_fn_test = DataCollatorWithPadding(tokenizer)\n",
    "test_batch_sampler = BatchSampler(actual_test_ds, batch_size=32, shuffle=False)\n",
    "actual_test_data_loader = DataLoader(dataset=actual_test_ds, batch_sampler=test_batch_sampler, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNIE 3.0-Medium 在my weibo datatest的表现 eval accu: 0.72222\n"
     ]
    }
   ],
   "source": [
    "# 加载ERNIR 3.0最佳模型参数\n",
    "params_path = 'ernie_ckpt_clean/model_state.pdparams'\n",
    "state_dict = paddle.load(params_path)\n",
    "model.set_dict(state_dict)\n",
    "\n",
    "print('ERNIE 3.0-Medium 在my weibo datatest的表现', end=' ')\n",
    "actual_eval_acc = evaluate(model, metric, actual_test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_env",
   "language": "python",
   "name": "paddle_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
